¡Claro! Aquí tienes tu README organizado y un poco más claro, con secciones bien definidas y con formato profesional. He añadido algunos detalles para mejorar la legibilidad y fluidez:

---

# Predicción del Happiness Score por País (2015-2019)

## Descripción del Proyecto

Este proyecto busca predecir el **Happiness Score** (índice de felicidad) de distintos países usando datos históricos desde 2015 hasta 2019. El flujo completo incluye:

* Recolección y limpieza de datos
* Entrenamiento de un modelo de regresión (Random Forest)
* Transmisión de datos en tiempo real con **Apache Kafka**
* Orquestación de servicios con **Docker** para facilitar la implementación y despliegue

---

## Estructura del Proyecto

```
WORKSHOP3/
│
├── config/
│   ├── __init__.py
│   └── conexion_db.py         # Conexión a base de datos PostgreSQL
│
├── cuaderno/
│   ├── 01_combine_data.ipynb  # Unión y limpieza de datos
│   ├── 02_EDA.ipynb           # Análisis exploratorio y visualización
│   ├── 03_modelo.ipynb        # Entrenamiento y evaluación del modelo
│   └── 04_db_model.ipynb      # Inserción de predicciones en la base de datos
│
├── datos/
│   ├── 2015.csv a 2019.csv    # Datos originales por año
│   ├── combined_happiness_data.csv  # Dataset combinado
│   └── datos_procesados.csv         # Datos limpios y listos para modelar
│
├── kafka/
│   ├── producer.py            # Productor Kafka que envía datos
│   └── consumer.py            # Consumidor Kafka que predice y almacena resultados
│
├── modelo/
│   └── mejor_modelo.pkl       # Modelo entrenado serializado
│
├── pdf/                       # Documentación adicional
│
├── .env                       # Variables de entorno sensibles
├── .gitignore
└── docker-compose.yml         # Orquestación de servicios con Docker
```

---

## Requerimientos

Para instalar las dependencias, crea y activa un entorno virtual y luego ejecuta:

```bash
python -m venv venv
# En Linux/Mac:
source venv/bin/activate
# En Windows (PowerShell):
venv\Scripts\activate

pip install -r requirements.txt
```

---

## Flujo de Trabajo

1. **Combinación y limpieza de datos**
   Ejecuta `cuaderno/01_combine_data.ipynb` para unir y limpiar los datos históricos.

2. **Análisis Exploratorio de Datos (EDA)**
   Visualiza y analiza variables en `cuaderno/02_EDA.ipynb` para entender mejor los datos.

3. **Entrenamiento del Modelo**
   Entrena y evalúa modelos de regresión en `cuaderno/03_modelo.ipynb`. El modelo final es un **Random Forest** con R² ≈ 0.89.

4. **Predicción y almacenamiento con Kafka**

   * Ejecuta `kafka/producer.py` para enviar datos procesados al tópico Kafka.
   * Ejecuta `kafka/consumer.py` para consumir datos, predecir el índice de felicidad y guardar resultados en PostgreSQL.

5. **Orquestación con Docker**
   Levanta los servicios (Kafka, Zookeeper, PostgreSQL) ejecutando:

   ```bash
   docker-compose up -d
   ```

---

## Cómo usar el proyecto

1. Levanta los servicios con Docker:

   ```bash
   docker-compose up -d
   ```

2. Verifica que los servicios estén activos:

   ```bash
   docker ps
   ```

3. Ejecuta el productor Kafka para enviar datos:

   ```bash
   python kafka/producer.py
   ```

4. Ejecuta el consumidor Kafka para predecir y guardar en base de datos:

   ```bash
   python kafka/consumer.py
   ```

---

## Base de Datos

* Sistema: **PostgreSQL**
* Tabla para almacenar:

  * Variables de entrada
  * Predicción del Happiness Score
  * Fecha y hora de la predicción
* La conexión está gestionada en `config/conexion_db.py` usando la librería `psycopg2`

---

## Contacto

* **Autor:** luzangelacarabali
* (Puedes agregar aquí tu correo, LinkedIn u otra forma de contacto si quieres)

